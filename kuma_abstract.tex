%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 前研スタイルファイル 設定部分
%
%    27行目までの項目を用いて表紙を生成しています．
%    学科のabstractスタイルが変更になった場合は，
%    27行目までの項目がすべてそろうようにスタイルファイルに
%    付け足してください
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%改行位置はそれぞれ自分で調節する
\表紙題目{
進行方向の計算回数削減による\\SFMを用いた人流シミュレーション\\の高速化
}

%名前の間は半角スペース
\和文氏名{片寄 颯人}
\英文氏名{KATAYOSE Hayato}

\学生番号{2281011}

\令和年度{5}
\西暦年度{2023}

\提出日{2023年12月24日} % 表紙だけじゃなくて謝辞でも使っているので注意


\和文題目{
進行方向の計算回数削減による\\SFMを用いた人流シミュレーションの高速化
}

%%%%%[ここから下は修士のみ記入]%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   アブストラクト用の設定
%       表紙と改行位置が異なる場合があるので注意！

%\修論false        %この行を消去(コメントアウトでもOK)すること

\表紙西暦{2022}
\英文題目{Accelerate matrix sum-of-products operations by\\ improving execution efficiency using \\stream processing in GPU kernels}

\和文キーワード{GPU，カーネル，ストリーム，Tesla V100，Tensorコア}
\英文キーワード{GPU，Kernel，Stream，Tesla V100，TensorCore}

\和文論文要旨={

本論文では，CUDAを用いた行列積和演算を高速化するために，CUDA機能の一つである
ストリームを用いてカーネルを複数発行し，実行スレッドブロック，ワープ数を増加することでGPUの計算実行効
率を向上する手法を提案する．

CUDAを用いた行列積和演算は，多数のスレッドを起動し，各要素の計算を並列実行する．
CUDAを用いた数値計算において，GPUの性能を最大限引き出すには，より多数のスレッドを起動し，
スレッドのまとまりであるワープやスレッドブロックをSMを占有された状態になるように確保する必要がある．

GPUアーキテクチャに最適化した手法として，cuBLASやCUTLASSといったGPU向け数値計算ライブラリがある．
 これらのライブラリでは，計算カーネルの実行性能を高めるために，レジスタやシェアードメモリといったリソースを
 最大限使用する行列積和ルーチンの実装が行われており，問題サイズが大きくなるほど使用するリソースが増加し，
リソースの制限により生成されるスレッドブロック数や，発行ワープ数が減少し，GPU実行効率が低下する．

そこで提案手法は，GPUのSM実行効率を向上するために，行列積和処理を分割し，実行カーネル数を増やし並列実行することで，
行列積和計算時間を短縮する．行列積和処理カーネルを，リソースを最大限利用して計算を行うカーネルと，使用リソースを最小限に抑えたカーネルに分割する．
各カーネルをストリーム処理し，SMにより多くのスレッドブロックを割り当てることによってSM実行効率を向上する．

 最後に，提案手法をNVIDIA Tesla V100で評価した．行列積和演算を対象とした評価の結果，
 ストリーム処理を使い計算カーネルを並列実行する手法は，Tensorコアのみを用いた手法と比べ，行列サイズ32000で最大約1.09倍高速化することが確認できた．
}% 600字程度


\英文論文要旨={

Write summary here.

}% about 200 words
